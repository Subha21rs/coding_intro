zim <- zeroinfl(count~.|., data=data, dist = "negbin",link='probit')
mu_hat <- predict(zim, type = "count")
pi_hat <- predict(zim, type = "zero")
theta <- zim$theta
n <- length(mu_hat)
k <- length(k_vals)
pred_probs <- matrix(NA, nrow = n, ncol = k)
for (i in 1:n) {
for (j in 1:k) {
y <- k_vals[j]
if (y == 0) {
pred_probs[i, j] <- pi_hat[i] + (1 - pi_hat[i]) * dnbinom(0, mu=mu_hat[i],size=theta)
} else {
pred_probs[i, j] <- (1 - pi_hat[i]) * dnbinom(y, mu=mu_hat[i], size=theta)
}
}
}
colnames(pred_probs) <- k_vals
pred_probs_df <- as.data.frame(pred_probs)
expected_probs <- colMeans(pred_probs_df)
diff_probs <- observed_probs_full - expected_probs
plot_df_zinb= data.frame(count=k_vals, difference=diff_probs)
y_pred=predict(zim,type='response')
y_pred=unname(y_pred)
plot(y,y_pred,xlab='y',ylab='y_pred',col='blue',pch=16)
abline(0,1,col='red',lty=2)
## plot the histogram of original y and predicted y
hist(y,col=rgb(1, 0, 0, alpha = 0.6),breaks=15)
hist(y_pred,col=rgb(0, 0, 1, alpha = 0.3),breaks=15,add=TRUE)
legend('topright',legend=c('y original','y predicted'),fill = c(rgb(1, 0, 0, alpha = 0.5), rgb(0, 0, 1, alpha = 0.5)))
######### Plot the 69 data models observed-pedicted probabilities ########
# Add model labels to each data frame
plot_df_poisson$model <- "PO"
plot_df_nb$model <- "NB"
plot_df_zip$model <- "ZIP"
plot_df_zinb$model <- "ZINB"
plot_df_hp$model <- "HP"
plot_df_hnb$model <- "HNB"
View(plot_df_hnb)
# Combine all into one
plot_df_all <- rbind(
plot_df_poisson,
plot_df_nb,
plot_df_zip,
plot_df_zinb,
plot_df_hp,
plot_df_hnb
)
View(plot_df_all)
View(plot_df_all)
cl <- c(cl1,cl2,cl3,cl4,cl5,cl6)
data<- read.csv('/Users/subha/Desktop/AIS_2025_code_session/coding_intro/data/example_data.csv')
x <- seq(0, 500, length.out = 32)
member=data[,33]
data=data[,-33]
cl1=colMeans( data[member==1,] )
cl2=colMeans( data[member==2,] )
cl3=colMeans( data[member==3,] )
cl4=colMeans( data[member==4,] )
cl5=colMeans( data[member==5,] )
cl6=colMeans( data[member==6,] )
cl <- c(cl1,cl2,cl3,cl4,cl5,cl6)
length(cl)
length(cl1)
32*6
x_rep= rep(x, times=6)
View(x_rep)
x_rep
cl <- c(cl1,cl2,cl3,cl4,cl5,cl6)
x_rep= rep(x, times=6)
class <- rep(c('class1','class2','class3','class4','class5','class6'), each=32)
df_plot <- data.frame(x=x_rep,y=cl,class=class)
View(plot_df_all)
cl <- c(cl1,cl2,cl3,cl4,cl5,cl6)
x_rep= rep(x, times=6)
class <- rep(c('class1','class2','class3','class4','class5','class6'), each=32)
df_plot <- data.frame(x=x_rep,y=cl,class=class)
plott69 = ggplot(df_plot, aes(x = x, y = y, color = class, shape=class)) +
geom_line() +
geom_point(size=3) +
geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
labs(x = "Time (ms)", y = "Amplitude", color =NULL, shape=NULL) +
scale_x_continuous(breaks = seq(0, 20, by = 1), limits = c(0,20)) +
scale_color_manual(values = c("PO" = "blue","NB" = "cyan","ZIP" = "azure4",
"ZINB" = "magenta","HP" = "green","HNB" = "red")) +
#scale_shape_manual(values = c("PO" = 16,   # solid circle
"NB" = 17,        # solid triangle
plott69 = ggplot(df_plot, aes(x = x, y = y, color = class, shape=class)) +
geom_line() +
geom_point(size=3) +
geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
labs(x = "Time (ms)", y = "Amplitude", color =NULL, shape=NULL) +
scale_x_continuous(breaks = seq(0, 20, by = 1), limits = c(0,20)) +
scale_color_manual(values = c("PO" = "blue","NB" = "cyan","ZIP" = "azure4",
"ZINB" = "magenta","HP" = "green","HNB" = "red")) +
#scale_shape_manual(values = c("PO" = 16,   # solid circle
# "NB" = 17,        # solid triangle
# "ZIP" = 15,       # solid square
# "ZINB" = 3,       # plus
# "HP" = 4, # cross
# "HNB" = 8   # star
)) +
plott69 = ggplot(df_plot, aes(x = x, y = y, color = class, shape=class)) +
geom_line() +
geom_point(size=3) +
geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
labs(x = "Time (ms)", y = "Amplitude", color =NULL, shape=NULL) +
scale_x_continuous(breaks = seq(0, 20, by = 1), limits = c(0,20)) +
scale_color_manual(values = c("PO" = "blue","NB" = "cyan","ZIP" = "azure4",
"ZINB" = "magenta","HP" = "green","HNB" = "red")) +
#scale_shape_manual(values = c("PO" = 16,   # solid circle
# "NB" = 17,        # solid triangle
# "ZIP" = 15,       # solid square
# "ZINB" = 3,       # plus
# "HP" = 4, # cross
# "HNB" = 8   # star
#)) +
theme_minimal()+
theme(
axis.title.x = element_text(size = 30),   # X label size
axis.title.y = element_text(size = 30),   # Y label size
axis.text.x = element_text(size = 18),    # X tick label size
axis.text.y = element_text(size = 18),     # Y tick label size
legend.text = element_text(size = 25),
legend.title = element_blank(),
panel.grid.minor.x = element_blank()
)
plott69
plott69 = ggplot(df_plot, aes(x = x, y = y, color = class, shape=class)) +
geom_line() +
geom_point(size=3) +
geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
labs(x = "Time (ms)", y = "Amplitude", color =NULL, shape=NULL) +
#scale_x_continuous(breaks = seq(0, 20, by = 1), limits = c(0,20)) +
scale_color_manual(values = c("PO" = "blue","NB" = "cyan","ZIP" = "azure4",
"ZINB" = "magenta","HP" = "green","HNB" = "red")) +
#scale_shape_manual(values = c("PO" = 16,   # solid circle
# "NB" = 17,        # solid triangle
# "ZIP" = 15,       # solid square
# "ZINB" = 3,       # plus
# "HP" = 4, # cross
# "HNB" = 8   # star
#)) +
theme_minimal()+
theme(
axis.title.x = element_text(size = 30),   # X label size
axis.title.y = element_text(size = 30),   # Y label size
axis.text.x = element_text(size = 18),    # X tick label size
axis.text.y = element_text(size = 18),     # Y tick label size
legend.text = element_text(size = 25),
legend.title = element_blank(),
panel.grid.minor.x = element_blank()
)
plott69
plott69 = ggplot(df_plot, aes(x = x, y = y, color = class, shape=class)) +
geom_line() +
geom_point(size=3) +
geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
labs(x = "Time (ms)", y = "Amplitude", color =NULL, shape=NULL) +
#scale_x_continuous(breaks = seq(0, 20, by = 1), limits = c(0,20)) +
scale_color_manual(values = c("class1" = "blue","class2" = "cyan","class3" = "azure4",
"class4" = "magenta","class5" = "green","class5" = "red")) +
#scale_shape_manual(values = c("PO" = 16,   # solid circle
# "NB" = 17,        # solid triangle
# "ZIP" = 15,       # solid square
# "ZINB" = 3,       # plus
# "HP" = 4, # cross
# "HNB" = 8   # star
#)) +
theme_minimal()+
theme(
axis.title.x = element_text(size = 30),   # X label size
axis.title.y = element_text(size = 30),   # Y label size
axis.text.x = element_text(size = 18),    # X tick label size
axis.text.y = element_text(size = 18),     # Y tick label size
legend.text = element_text(size = 25),
legend.title = element_blank(),
panel.grid.minor.x = element_blank()
)
plott69
plott69 = ggplot(df_plot, aes(x = x, y = y, color = class)) +
geom_line() +
geom_point(size=3) +
geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
labs(x = "Time (ms)", y = "Amplitude", color =NULL, shape=NULL) +
#scale_x_continuous(breaks = seq(0, 20, by = 1), limits = c(0,20)) +
scale_color_manual(values = c("class1" = "blue","class2" = "cyan","class3" = "azure4",
"class4" = "magenta","class5" = "green","class5" = "red")) +
#scale_shape_manual(values = c("PO" = 16,   # solid circle
# "NB" = 17,        # solid triangle
# "ZIP" = 15,       # solid square
# "ZINB" = 3,       # plus
# "HP" = 4, # cross
# "HNB" = 8   # star
#)) +
theme_minimal()+
theme(
axis.title.x = element_text(size = 30),   # X label size
axis.title.y = element_text(size = 30),   # Y label size
axis.text.x = element_text(size = 18),    # X tick label size
axis.text.y = element_text(size = 18),     # Y tick label size
legend.text = element_text(size = 25),
legend.title = element_blank(),
panel.grid.minor.x = element_blank()
)
plott69
plott69 = ggplot(df_plot, aes(x = x, y = y, color = class)) +
geom_line() +
#geom_point(size=3) +
geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
labs(x = "Time (ms)", y = "Amplitude", color =NULL, shape=NULL) +
#scale_x_continuous(breaks = seq(0, 20, by = 1), limits = c(0,20)) +
scale_color_manual(values = c("class1" = "blue","class2" = "cyan","class3" = "azure4",
"class4" = "magenta","class5" = "green","class5" = "red")) +
#scale_shape_manual(values = c("PO" = 16,   # solid circle
# "NB" = 17,        # solid triangle
# "ZIP" = 15,       # solid square
# "ZINB" = 3,       # plus
# "HP" = 4, # cross
# "HNB" = 8   # star
#)) +
theme_minimal()+
theme(
axis.title.x = element_text(size = 30),   # X label size
axis.title.y = element_text(size = 30),   # Y label size
axis.text.x = element_text(size = 18),    # X tick label size
axis.text.y = element_text(size = 18),     # Y tick label size
legend.text = element_text(size = 25),
legend.title = element_blank(),
panel.grid.minor.x = element_blank()
)
plott69
?rt
##### simulation
#set.seed(13)
t_vals= rt(1000, df=10)
hist(t_vals, breaks=30,main='t-distribution')
##### simulation
#set.seed(13)
t_vals= rt(10000, df=10)
hist(t_vals, breaks=30,main='t-distribution')
##### simulation
#set.seed(13)
t_vals= rt(100, df=10)
hist(t_vals, breaks=30,main='t-distribution')
##### simulation
#set.seed(13)
t_vals= rt(10, df=10)
hist(t_vals, breaks=30,main='t-distribution')
####### Hypothesis testing
t.test(mpg ~ am, data = mtcars)
####### Hypothesis testing
t_test= t.test(mpg ~ am, data = mtcars)
summary(t_test)
t_test
wilcox.test(mpg ~ am, data = mtcars)
# from normal distribution
x <- rnorm(1000, mean = 10, sd = 2)
hist(x, breaks = 30, main = "Normal distribution", col = "blue")
# from multivariate normal
mu <- c(5,10)
sigma <- matrix(c(4,2,2,3), nrow=2)
sample = mvrnorm(n=1000, mu=mu,Sigma=sigma)
head(sample)
View(sample)
############Logistic regression
data(iris)
iris_bin= subset(iris, Species!='setosa')
View(iris_bin)
iris$Species <- factor(iris_bin$Species)
iris$Species <- factor(iris_bin$Species)
iris_bin$Species <- factor(iris_bin$Species)
View(iris_bin)
set.seed(1)
train_index<-sample(seq_len(nrow(iris_bin)),size=0.7*nrow(iris_bin))
train_index
nrow(iris_bin)),size=0.7*nrow(iris_bin)
seq_len(nrow(iris_bin))
?seq_len
train_index<-sample( seq_len(nrow(iris_bin)), size=0.7*nrow(iris_bin))
train_data <- iris_bin[sample_idx, ]
train_data <- iris_bin[sample_index, ]
train_data <- iris_bin[train_index, ]
test_data  <- iris_bin[-train_index, ]
model <- glm(Species ~ .,
data = train_data, family = binomial)
summary(model)
pred_prob<-predict(model,newdata = test_data,type='response')
pred_probs_df
pred_prob
pred_class <- ifelse(pred_probs > 0.5, "virginica", "versicolor")
pred_class
View(pred_class)
View(pred_class)
View(pred_class)
View(pred_class)
dim(pred_class)
View(pred_prob)
dim(pred_prob)
length(pred_prob)
pred_prob<-predict(model,newdata = test_data,type='response')
pred_class <- ifelse(pred_probs > 0.5, "virginica", "versicolor")
View(pred_probs)
View(pred_probs)
length(pred_prob)
pred_prob)
pred_prob
dim(pred_class)
actual <- ifelse(test_data$Species == "virginica", 1, 0)
predicted <- ifelse(pred_prob>0.5, 1, 0)
table(Predicted=predicted,Actual=actual)
acc=mean(predicted==actual)
print(acc)
data<- read.csv('/data/example_data.csv')
data<- read.csv('data/example_data.csv')
View(data)
######### Importing data
data<- read.csv('/home/kd/Downloads/AIS_2025_code_session/example_data.csv')
######### Importing data
data<- read.csv('data/example_data.csv')
head(data)
############ 3D plots using plotly
#install.packages("plotly")
library(plotly)
# Sample 3D data (from iris)
plot_ly(data = iris,
x = ~Sepal.Length,
y = ~Petal.Length,
z = ~Sepal.Width,
color = ~Species,
colors = c("red", "green", "blue"),
type = "scatter3d",
mode = "markers",
marker = list(size = 5, opacity = 0.8)) %>%
layout(title = "3D Scatterplot of Iris Data",
scene = list(
xaxis = list(title = 'Sepal Length'),
yaxis = list(title = 'Petal Length'),
zaxis = list(title = 'Sepal Width')
))
# surface plot
x <- seq(-10, 10, length.out = 50)
y <- seq(-10, 10, length.out = 50)
z <- outer(x, y, function(x, y) sin(sqrt(x^2 + y^2)))  # z = sin(sqrt(x² + y²))
View(z)
# Plot the surface
plot_ly(x = ~x, y = ~y, z = ~z) %>%
add_surface(colorscale = 'Viridis') %>%
layout(title = "3D Surface Plot of sin(sqrt(x² + y²))",
scene = list(
xaxis = list(title = "X"),
yaxis = list(title = "Y"),
zaxis = list(title = "Z")
))
####### PCA
data(iris)
iris_numeric <- iris[, 1:4]
pca <- prcomp(iris_numeric, scale. = TRUE)
summary(pca)
biplot(pca, col = c("gray", "red"))
?biplot
set.seed(1)
kmeans_result <- kmeans(iris[, 1:4], centers = 3)
table(kmeans_result$cluster, iris$Species)
# Visualize
library(cluster)
clusplot(iris[, 1:4], kmeans_result$cluster, color = TRUE, shade = TRUE, labels = 2)
?cluster
?clustplot
?clusplot
View(pca)
View(pca)
plot(pca$x[, 1], pca$x[, 2],
col = as.numeric(iris$Species),
pch = 19,
xlab = "PC1",
ylab = "PC2",
main = "PCA: PC1 vs PC2")
legend("topright", legend = levels(iris$Species),
col = 1:3, pch = 19)
plot(pca$x[, 1], pca$x[, 2],
col = as.numeric(iris$Species),
pch = 19,
xlab = "PC1",
ylab = "PC2",
main = "PCA: PC1 vs PC2")
legend("topright", legend = levels(iris$Species),
col = 1:3, pch = 19,cex=0.7)
?prcomp
####### Input, Output statement
var1= readline('Enter a number:')
var2==readline('Enter another number:')
var2=readline('Enter another number:')
print(var1+var2)
var1=as.numeric(var1)
var2=as.numeric(var2)
print(var1+var2)
####### ANOVA
# one way anova
library(dplyr)
head(mtcars)
aov1 <- aov(mtcars$disp~factor(mtcars$gear))
summary(mtcars_aov)
summary(aov1)
# two way anova
# Variance in mean within group and between group
histogram(mtcars$disp~mtcars$gear, subset = (mtcars$am == 0),
xlab = "gear", ylab = "disp", main = "Automatic")
####### ANOVA
# one way anova
library(dplyr)
# two way anova
# Variance in mean within group and between group
histogram(mtcars$disp~mtcars$gear, subset = (mtcars$am == 0),
xlab = "gear", ylab = "disp", main = "Automatic")
# two way anova
# Variance in mean within group and between group
hist(mtcars$disp~mtcars$gear, subset = (mtcars$am == 0),
xlab = "gear", ylab = "disp", main = "Automatic")
?histogram
?hist
aov2 <- aov(mtcars$disp~factor(mtcars$gear) *
factor(mtcars$am))
summary(aov2)
# two way anova
# Variance in mean within group and between group
# For automatic transmission
hist(mtcars$disp[mtcars$am == 0] ~ mtcars$gear[mtcars$am == 0],
xlab = "Gear", ylab = "Disp", main = "Automatic Transmission",
col = "lightblue", border = "black")
# two way anova
# Variance in mean within group and between group
# For automatic transmission
# For automatic transmission
hist(mtcars$disp[mtcars$am == 0],
xlab = "Disp", ylab = "Frequency", main = "Automatic Transmission",
col = "lightblue", border = "black", breaks = 10)
# two way anova
# Variance in mean within group and between group
# For automatic transmission
# For automatic transmission
hist(mtcars$disp[mtcars$am == 0],
xlab = "Disp", ylab = "Frequency", main = "Automatic Transmission",
col = "lightblue", border = "black", breaks = 10)
# For manual transmission
hist(mtcars$disp[mtcars$am == 1],
xlab = "Disp", ylab = "Frequency", main = "Manual Transmission",
col = "lightgreen", border = "black", breaks = 10)
aov2 <- aov(mtcars$disp~factor(mtcars$gear) *
factor(mtcars$am))
summary(aov2)
head(mtcars)
aov1 <- aov(mpg ~ factor(gear), data=mtcars)
summary(aov1)
# two way anova
aov2 <- aov(mgp ~ factor(gear) *
factor(am),data=mtcars)
summary(aov2)
# two way anova
aov2 <- aov(mpg ~ factor(gear) *
factor(am),data=mtcars)
summary(aov2)
# two way anova
aov2 <- aov(mpg ~ factor(gear) * factor(am),data=mtcars)
summary(aov2)
############ LDA
library(MASS)
############ LDA
library(MASS)
set.seed(123)
n <- 100
mu1 <- c(1, 2)
mu2 <- c(5, 6)
sigma <- matrix(c(1, 0.5, 0.5, 1), nrow = 2)
class1 <- mvrnorm(n, mu = mu1, Sigma = sigma)
class2 <- mvrnorm(n, mu = mu2, Sigma = sigma)
data <- rbind(class1, class2)
labels <- factor(c(rep(0, n), rep(1, n)))
df <- data.frame(data, class = labels)
names(df) <- c("X1", "X2", "Class")
set.seed(123)
train_indices <- sample(1:nrow(df), size = 0.7 * nrow(df))
trainData <- df[train_indices, ]
testData <- df[-train_indices, ]
lda_model <- lda(Class ~., data = trainData)
lda_pred <- predict(lda_model, testData)
predicted_class <- lda_pred$class
confusion_matrix <- table(predicted_class, testData$Class)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
(confusion_matrix <- table(predicted_class, testData$Class))
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
n <- 100
mu1 <- c(1, 2)
mu2 <- c(3, 4)
sigma <- matrix(c(1, 0.5, 0.5, 1), nrow = 2)
class1 <- mvrnorm(n, mu = mu1, Sigma = sigma)
class2 <- mvrnorm(n, mu = mu2, Sigma = sigma)
data <- rbind(class1, class2)
labels <- factor(c(rep(0, n), rep(1, n)))
df <- data.frame(data, class = labels)
names(df) <- c("X1", "X2", "Class")
set.seed(123)
train_indices <- sample(1:nrow(df), size = 0.7 * nrow(df))
trainData <- df[train_indices, ]
testData <- df[-train_indices, ]
lda_model <- lda(Class ~., data = trainData)
lda_pred <- predict(lda_model, testData)
predicted_class <- lda_pred$class
(confusion_matrix <- table(predicted_class, testData$Class))
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
